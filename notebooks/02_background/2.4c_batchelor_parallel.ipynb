{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b684ba",
   "metadata": {},
   "source": [
    "# Batchelor Cornerflow Example\n",
    "\n",
    "Author: Cian Wilson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0419ee73-1291-4e12-8641-425a71e331c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Description\n",
    "\n",
    "As a reminder we are seeking the approximate velocity and pressure solution of the Stokes equation\n",
    "\\begin{align}\n",
    "-\\nabla\\cdot \\left(\\frac{\\nabla\\tilde{\\vec{v}} + \\nabla\\tilde{\\vec{v}}^T}{2}\\right) + \\nabla \\tilde{P} &= 0 && \\text{in }\\Omega \\\\\n",
    "\\nabla\\cdot\\tilde{\\vec{v}} &= 0 && \\text{in }\\Omega\n",
    "\\end{align}\n",
    "in a unit square domain, $\\Omega = [0,1]\\times[0,1]$.\n",
    "\n",
    "We apply strong Dirichlet boundary conditions for velocity on all four boundaries\n",
    "\\begin{align}\n",
    "  \\tilde{\\vec{v}} &= (0,0)^T && \\text{on } \\partial\\Omega \\text{ where } x=0  \\\\\n",
    "  \\tilde{\\vec{v}} &= (U, 0)^T  && \\text{on } \\partial\\Omega \\text{ where } y=0 \\\\\n",
    "  \\tilde{\\vec{v}} &= \\vec{v} && \\text{on } \\partial\\Omega \\text{ where } x=1 \\text{ or } y = 1\n",
    "\\end{align}\n",
    "and a constraint on the pressure to remove its null space, e.g. by applying a reference point\n",
    "\\begin{align}\n",
    "  P &= 0 && \\text{at } (x, y) = (0,0)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfefe9ba",
   "metadata": {},
   "source": [
    "## Parallel Scaling\n",
    "\n",
    "In [the previous notebook](./2.4b_batchelor.ipynb) we tested that the error in our implementation of a Batchelor corner-flow problem in two-dimensions converged as the number of elements increased and found suboptimal results owing to the discontinuous boundary conditions imposed in this problem.  We also wish to test for parallel scaling of this problem, assessing if the simulation wall time decreases as the number of processors used to solve it is increases.\n",
    "\n",
    "Here we perform strong scaling tests on our function `solve_batchelor` from [`notebooks/02_background/2.4b_batchelor.ipynb`](./2.4b_batchelor.ipynb).  As we will see this is more challenging than in the [2D Poisson](./2.3d_poisson_2d_parallel.ipynb) case as the solution algorithm must deal with the pressure null space and the fact that we are seeking the solution to a saddle-point problem with a zero diagonal block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de751f09",
   "metadata": {},
   "source": [
    "### Preamble\n",
    "\n",
    "We start by loading all the modules we will require."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "basedir = ''\n",
    "if \"__file__\" in globals(): basedir = os.path.dirname(__file__)\n",
    "path = os.path.join(basedir, os.path.pardir, os.path.pardir, 'python')\n",
    "sys.path.append(path)\n",
    "import utils.ipp\n",
    "from background.batchelor import test_plot_convergence\n",
    "import pathlib\n",
    "output_folder = pathlib.Path(os.path.join(basedir, \"output\"))\n",
    "output_folder.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59cc057",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "We perform the strong parallel scaling test using a utility function (from `python/utils/ipp.py`) that loops over a list of the number of processors calling our function for a given number of elements, `ne`, and polynomial order `p`.  It runs our function `solve_batchelor` a specified `number` of times and evaluates and returns the time taken for each of a number of requested `steps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c94d1",
   "metadata": {
    "tags": [
     "main"
    ]
   },
   "outputs": [],
   "source": [
    "# the list of the number of processors we will use\n",
    "nprocs_scale = [1, 2, 4]\n",
    "\n",
    "# the number of elements to solve the problem on\n",
    "ne = 128\n",
    "\n",
    "# the polynomial degree of our pressure field\n",
    "p = 1\n",
    "\n",
    "# perform the calculation a set number of times\n",
    "number = 1\n",
    "\n",
    "# We are interested in the time to create the mesh,\n",
    "# declare the functions, assemble the problem and solve it.\n",
    "# From our implementation in `solve_poisson_2d` it is also\n",
    "# possible to request the time to declare the Dirichlet and\n",
    "# Neumann boundary conditions and the forms.\n",
    "steps = [\n",
    "          'Mesh', 'Function spaces',\n",
    "          'Assemble', 'Solve',\n",
    "         ]\n",
    "\n",
    "# declare a dictionary to store the times each step takes\n",
    "maxtimes = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e07621",
   "metadata": {},
   "source": [
    "#### Direct\n",
    "\n",
    "To start with we test the scaling with the default solver options, which is a direct LU decomposition using the MUMPS library implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba7fba-4cb9-412d-9284-7e2c9946ec73",
   "metadata": {
    "tags": [
     "main"
    ]
   },
   "outputs": [],
   "source": [
    "maxtimes['Direct'] = utils.ipp.profile_parallel(nprocs_scale, steps, path, 'background.batchelor', 'solve_batchelor', \n",
    "                                                ne, p, number=number,\n",
    "                                                output_filename=output_folder / 'batchelor_scaling_direct_block.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1038bd3-b0a8-4a5a-bd3d-f395774eae48",
   "metadata": {},
   "source": [
    "\"Speed up\" is defined as the wall time on a given number of processors divided by the wall time on the smallest number of processors.  Ideally this should increase linearly with the number of processors with slope 1.  Such ideal scaling is rarely realized due to factors like the increasing costs of communication between processors but the behavior of the scaling test will also strongly depend on the computational resources available on the machine where this notebook is run.  In particular when the website is generated it has to run as quickly as possible on github, hence we limit our requested numbers of processors, size of the problem (`ne` and `p`) and number of calculations to average over (`number`) in the default setup of this notebook.\n",
    "\n",
    "For comparison we provide the output of this notebook using `ne = 256`, `p = 1` and `number = 10` in Figure 2.4.2 generated on a dedicated machine using a local [conda](../01_introduction/1.1_overview.ipynb) installation of the software.\n",
    "\n",
    "![Direct Scaling](images/batchelor_scaling_direct_block.png)\n",
    "\n",
    "*Figure 2.4.2 Scaling results for a direct solver with `ne = 256`, `p = 1` averaged over `number = 10` calculations using a local [conda](../01_introduction/1.1_overview.ipynb) installation of the software on a dedicated machine.*\n",
    "\n",
    "As in the [Poisson 2D](./2.3d_poisson_2d_parallel.ipynb) case we can see that assembly and function space declarations scale well, with assembly being almost ideal.  However meshing and the solve barely scale at all.  The meshing takes place on a single process before being communicated to the other processors, hence we do not expect this step to scale.  Additionally the cost (wall time taken) of meshing is so small that it is not a significant factor in these simulations.  However the solution step is our most significant cost and would ideally scale.  Its failure to do so here is a result of an initial analysis step that is performed in serial (on a single processor), the significance of which will decrease once the solver is used more than once per simulation.\n",
    "\n",
    "Switching to alternative solvers is not as simple for the Stokes system as it was in the [Poisson 2D](./2.3d_poisson_2d_parallel.ipynb) example.  We need to modify our implementation because\n",
    " 1. we are solving a saddle point system with a zero pressure block in the matrix\n",
    " 2. each block (for the velocity and pressure) of the matrix would ideally be preconditioned differently to get the best iterative solver convergence behavior\n",
    " 3. our solver must be able to deal with the pressure null space\n",
    "\n",
    "We will try this in the [next notebook](./2.4d_batchelor_nest.ipynb) but first we will check that the solution using a direct solver is still converging in parallel.  We do this by running our convergence test from [`notebooks/02_background/2.4b_batchelor.ipynb`](./2.4b_batchelor.ipynb) in parallel using the utility function `utils.ipp.run_parallel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21591bf2",
   "metadata": {
    "tags": [
     "main"
    ]
   },
   "outputs": [],
   "source": [
    "# the list of the number of processors to test the convergence on\n",
    "nprocs_conv = [2,]\n",
    "# List of polynomial orders to try\n",
    "ps = [1, 2]\n",
    "# List of resolutions to try\n",
    "nelements = [10, 20, 40, 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f8faf",
   "metadata": {
    "tags": [
     "main"
    ]
   },
   "outputs": [],
   "source": [
    "errors_l2_all = utils.ipp.run_parallel(nprocs_conv, path, 'background.batchelor', 'convergence_errors', ps, nelements)\n",
    "\n",
    "for errors_l2 in errors_l2_all:\n",
    "    test_passes = test_plot_convergence(ps, nelements, errors_l2)\n",
    "    assert(test_passes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ce5c4-7981-49b5-94e4-58486669436f",
   "metadata": {},
   "source": [
    "We can see that, even in parallel, we reproduce the (suboptimal) convergence of the problem in [serial](./2.4b_batchelor.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6faaec2-e379-46a6-b5f7-823f2ece5cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
