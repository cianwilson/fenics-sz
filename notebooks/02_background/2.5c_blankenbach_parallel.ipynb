{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b684ba",
   "metadata": {},
   "source": [
    "# Blankenbach Thermal Convection Example\n",
    "\n",
    "Author: Cian Wilson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e36029f",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "As a reminder we are seeking the approximate velocity, pressure and temperature solutions of the coupled Stokes\n",
    "\\begin{align}\n",
    "    - \\nabla\\cdot\\left(2\\eta\\frac{\\nabla\\vec{v} + \\nabla\\vec{v}^T}{2}\\right) + \\nabla P &= -\\textrm{Ra}~T \\hat{\\vec{g}} && \\text{in } \\Omega  \\\\\n",
    "    \\nabla \\cdot \\vec{v} &= 0  && \\text{in } \\Omega \n",
    "\\end{align}\n",
    "and heat equations\n",
    "\\begin{align}\n",
    "\\vec{v} \\cdot \\nabla T &= \\nabla^2 T  && \\text{in } \\Omega  \n",
    "\\end{align}\n",
    "in a bottom-heated unit square domain, $\\Omega$, with boundaries, $\\partial\\Omega$.\n",
    "\n",
    "For the Stokes problem we assume free-slip boundaries\n",
    "\\begin{align}\n",
    "  \\tilde{\\vec{v}}\\cdot{\\hat{\\vec{n}}} &= 0 && \\text{on } \\partial\\Omega \\\\\n",
    "  \\hat{\\vec{t}}\\cdot\n",
    "\\begin{bmatrix}\n",
    "2\\eta\\frac{\\partial \\tilde{v}_x}{\\partial x} & \\eta \\left( \\frac{\\partial \\tilde{v}_x}{\\partial y} + \\frac{\\partial \\tilde{v}_y}{\\partial x} \\right) \\\\\n",
    "\\eta \\left( \\frac{\\partial \\tilde{v}_x}{\\partial y} + \\frac{\\partial \\tilde{v}_y}{\\partial x} \\right) & 2\\eta\\frac{\\partial \\tilde{v}_y}{\\partial y}\n",
    "\\end{bmatrix}\n",
    "\\cdot\\hat{\\vec{n}} &= 0 && \\text{on } \\partial\\Omega\n",
    "\\end{align}\n",
    "and constrain the pressure to remove its null space, e.g. by applying a reference point\n",
    "\\begin{align}\n",
    "  P &= 0 && \\text{at } (x, y) = (0,0)\n",
    "\\end{align}\n",
    "\n",
    "For the heat equation the side boundaries are insulating, the base hot and the base cold\n",
    "\\begin{align}\n",
    "  \\frac{\\partial\\tilde{T}}{\\partial t} &= 0 && \\text{on } \\partial\\Omega \\text{ where } x=0 \\text{ or } x=1  \\\\\n",
    "  \\tilde{T} &= 1 && \\text{on } \\partial\\Omega \\text{ where } y=0 \\\\\n",
    "  \\tilde{T} &= 0 && \\text{on } \\partial\\Omega \\text{ where } y=1\n",
    "\\end{align}\n",
    "\n",
    "We seek solutions at a variety of Rayleigh numbers, Ra, and consider both isoviscous, $\\eta = 1$, cases and a case with a temperature-dependent viscosity, $\\eta(T) = \\exp(-bT)$ with $b=\\ln(10^3)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ead04",
   "metadata": {},
   "source": [
    "## Parallel Scaling\n",
    "\n",
    "In [the previous notebook](./2.5b_blankenbach.ipynb) we tested that the error in our implementation of a steady-state thermal convection problem in two-dimensions converged towards the published benchmark value as the number of elements increased.  We also wish to test for parallel scaling of this problem, assessing if the simulation wall time decreases as the number of processors used to solve it increases.\n",
    "\n",
    "Here we perform strong scaling tests on our function `solve_blankenbach` from [`notebooks/02_background/2.5b_blankenbach.ipynb`](./2.5b_blankenbach.ipynb).  We will see that as we perform multiple solves in the Picard iteration the advantages of an iterative solver are eclipsed for this simple 2D case as the direct solver can reuse its initial expensive analysis step on subsequent solves.  This also helps to overcome some of the poor scaling we observed using the direct solver in previous examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d312acf5",
   "metadata": {},
   "source": [
    "### Preamble\n",
    "\n",
    "We start by loading all the modules we will require."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052bfcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "basedir = ''\n",
    "if \"__file__\" in globals(): basedir = os.path.dirname(__file__)\n",
    "path = os.path.join(basedir, os.path.pardir, os.path.pardir, 'python')\n",
    "sys.path.append(path)\n",
    "import utils.ipp\n",
    "from background.blankenbach import plot_convergence\n",
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "import pathlib\n",
    "output_folder = pathlib.Path(os.path.join(basedir, \"output\"))\n",
    "output_folder.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc8cef9",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "We perform the strong parallel scaling test using a utility function (from `python/utils/ipp.py`) that loops over a list of the number of processors calling our function for a given number of elements, `ne`, and pressure and temperature polynomial orders `pp` and `pT`.  It runs our function `solve_blankenbach` a specified `number` of times and evaluates and returns the time taken for each of a number of requested `steps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e81268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list of the number of processors we will use\n",
    "nprocs_scale = [1, 2, 4]\n",
    "\n",
    "# the number of elements to solve the problem on\n",
    "ne = 128\n",
    "\n",
    "# the polynomial degree of our pressure field\n",
    "pp = 1\n",
    "# the polynomial degree of our temperature field\n",
    "pT = 1\n",
    "\n",
    "# grid refinement factor\n",
    "beta = 0.2\n",
    "\n",
    "# perform the calculation a set number of times\n",
    "number = 1\n",
    "\n",
    "# We are interested in the time to create the mesh,\n",
    "# declare the functions, assemble the problem and solve it.\n",
    "# From our implementation in `solve_poisson_2d` it is also\n",
    "# possible to request the time to declare the Dirichlet and\n",
    "# Neumann boundary conditions and the forms.\n",
    "steps = [\n",
    "          'Assemble Temperature', 'Assemble Stokes',\n",
    "          'Solve Temperature', 'Solve Stokes'\n",
    "         ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf631dc",
   "metadata": {},
   "source": [
    "#### Case 1a - Direct\n",
    "\n",
    "We start by running case 1a - isoviscous with Ra $=10^4$ - and will compare direct and iterative solver strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7cd1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare a dictionary to store the times each step takes\n",
    "maxtimes_1a = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe9960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 1a\n",
    "Ra = 1.e4\n",
    "b = None # isoviscous\n",
    "\n",
    "maxtimes_1a['Direct Stokes'] = utils.ipp.profile_parallel(nprocs_scale, steps, path, 'background.blankenbach', 'solve_blankenbach', \n",
    "                                                        Ra, ne, pp=pp, pT=pT, b=b, beta=beta, number=number,\n",
    "                                                        output_filename=output_folder / 'blankenbach_scaling_direct_1a.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07baadf5-3204-4ff0-9e3d-78b4e33dac87",
   "metadata": {},
   "source": [
    "The behavior of the scaling test will strongly depend on the computational resources available on the machine where this notebook is run.  In particular when the website is generated it has to run as quickly as possible on github, hence we limit our requested numbers of processors, size of the problem (`ne` and `p`) and number of calculations to average over (`number`) in the default setup of this notebook.\n",
    "\n",
    "For comparison we provide the output of this notebook using `ne = 256`, `pT = pp = 1`, `beta = 0.2` and `number = 10` in Figure 2.5.2 generated on a dedicated machine using a local [conda](../01_introduction/1.1_overview.ipynb) installation of the software.\n",
    "\n",
    "![Direct Scaling](images/blankenbach_scaling_direct_1a.png)\n",
    "\n",
    "*Figure 2.5.2 Scaling results for a direct solver with `ne = 256`, `pT = pp = 1`, `beta = 0.2` averaged over `number = 10` calculations using a local [conda](../01_introduction/1.1_overview.ipynb) installation of the software on a dedicated machine.*\n",
    "\n",
    "We can see in Figure 2.5.2 that assembly scales well.  Unlike in previous scaling tests we see that the solves also scale a little though far from ideally.  This is because the expensive analysis step performed in serial (that prevented scaling on previous single solve cases) can be reused on subsequent solves within the Picard iteration of the Blankenbach problem, reducing the impact on the scaling and wall times.\n",
    "\n",
    "We also need to test that we are still converging to the benchmark solutions in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4178bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list of the number of processors to test the convergence on\n",
    "nprocs_conv = [2,]\n",
    "\n",
    "# List of polynomial orders to try\n",
    "pTs = [1]\n",
    "# List of resolutions to try\n",
    "nelements = [32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf34b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = ['1a']\n",
    "errors_all = utils.ipp.run_parallel(nprocs_conv, path, 'background.blankenbach', 'convergence_errors', pTs, nelements, cases, beta=beta)\n",
    "\n",
    "for errors in errors_all:\n",
    "    fits = plot_convergence(pTs, nelements, errors)\n",
    "    assert(all(fit > 1.0 for fits_p in fits.values() for fits_l in fits_p for fit in fits_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe0a6c-f8b9-4473-9e03-afb1268a0c7f",
   "metadata": {},
   "source": [
    "#### Case 1a - Iterative\n",
    "\n",
    "In the previous [cornerflow example](./2.4e_batchelor_nest_parallel.ipynb) the iterative solver overcame the scaling issues of the direct method so we once again test that strategy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef9f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1a\n",
    "Ra = 1.e4\n",
    "b=None\n",
    "petsc_options_s = {'ksp_type':'minres', \n",
    "                   'ksp_rtol': 5.e-8,\n",
    "                   'pc_type':'fieldsplit', \n",
    "                   'pc_fieldsplit_type': 'additive',\n",
    "                   'fieldsplit_v_ksp_type':'preonly',\n",
    "                   'fieldsplit_v_pc_type':'gamg',\n",
    "                   'fieldsplit_p_ksp_type':'preonly',\n",
    "                   'fieldsplit_p_pc_type':'jacobi'}\n",
    "\n",
    "maxtimes_1a['Iterative (1a)'] = utils.ipp.profile_parallel(nprocs_scale, steps, path, 'background.blankenbach', 'solve_blankenbach', \n",
    "                                                        Ra, ne, pp=pp, pT=pT, b=b, beta=beta, \n",
    "                                                        petsc_options_s=petsc_options_s, \n",
    "                                                        attach_nullspace=True, \n",
    "                                                        number=number,\n",
    "                                                        output_filename=output_folder / 'blankenbach_scaling_iterative_1a.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fda781d-7bd5-480c-ba20-443134d1ebe1",
   "metadata": {},
   "source": [
    "If sufficient computational resources are available when running this notebook (unlikely during website generation) this should show that the iterative method scales better than the direct method but has a much higher absolute cost (wall time).  \n",
    "\n",
    "For reference we provide the output of this notebook using `ne = 256`, `pT = pp = 1`, `beta = 0.2` and `number = 10` in Figure 2.5.3 generated on a dedicated machine using a local [conda](../01_introduction/1.1_overview.ipynb) installation of the software.\n",
    "\n",
    "![Iterative Scaling](images/blankenbach_scaling_iterative_1a.png)\n",
    "\n",
    "*Figure 2.5.3 Scaling results for a direct solver with `ne = 256`, `pT = pp = 1`, `beta = 0.2` averaged over `number = 10` calculations using a local [conda](../01_introduction/1.1_overview.ipynb) installation of the software on a dedicated machine.*\n",
    "\n",
    "Here we can see the improved scaling (for the Stokes solve, the temperature is still using a direct method) but increased cost.  This is because each application of the iterative method selected here has roughly the same cost whereas the cost of the direct method reduces significantly on reapplication in later Picard iterations.  Here we are performing roughly 10 iterations, which scales approximately with the relative costs of the two methods seen here.\n",
    "\n",
    "We also test if the iterative method is converging to the benchmark solution below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = ['1a']\n",
    "errors_all = utils.ipp.run_parallel(nprocs_conv, path, \n",
    "                                    'background.blankenbach', 'convergence_errors', pTs, nelements, cases, beta=beta,\n",
    "                                    petsc_options_s=petsc_options_s, \n",
    "                                    attach_nullspace=True)\n",
    "\n",
    "for errors in errors_all:\n",
    "    fits = plot_convergence(pTs, nelements, errors)\n",
    "    assert(all(fit > 1.0 for fits_p in fits.values() for fits_l in fits_p for fit in fits_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0854c077-8c3b-4d8a-8772-462e7477957a",
   "metadata": {},
   "source": [
    "#### Case 1a - Comparison\n",
    "\n",
    "We can more easily compare the different solution method directly by plotting their walltimes for assembly and solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b394bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose which steps to compare\n",
    "compare_steps = ['Assemble Stokes', 'Solve Stokes']\n",
    "\n",
    "# set up a figure for plotting\n",
    "fig, axs = pl.subplots(nrows=len(compare_steps), figsize=[6.4,4.8*len(compare_steps)], sharex=True)\n",
    "if len(compare_steps) == 1: axs = [axs]\n",
    "for i, step in enumerate(compare_steps):\n",
    "    s = steps.index(step)\n",
    "    for name, lmaxtimes in maxtimes_1a.items():\n",
    "        axs[i].plot(nprocs_scale, [t[s] for t in lmaxtimes], 'o-', label=name)\n",
    "    axs[i].set_title(step)\n",
    "    axs[i].legend()\n",
    "    axs[i].set_ylabel('wall time (s)')\n",
    "    axs[i].grid()\n",
    "axs[-1].set_xlabel('number processors')\n",
    "# save the figure\n",
    "fig.savefig(output_folder / 'blankenbach_scaling_comparison_1a.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849eaf4d-07e4-4773-b010-7ece4f98d391",
   "metadata": {},
   "source": [
    "With sufficient computational resources we will see that both methods have approximately the same assembly costs but the iterative methods wall time costs are substantially higher and never become competitive despite scaling better at higher number of processors.\n",
    "\n",
    "For reference we provide the output of this notebook using `ne = 256`, `pT = pp = 1`, `beta = 0.2` and `number = 10` in Figure 2.5.4 generated on a dedicated machine using a local [conda](../01_introduction/1.1_overview.ipynb) installation of the software.\n",
    "\n",
    "![Scaling Comparison](images/blankenbach_scaling_comparison_1a.png)\n",
    "\n",
    "*Figure 2.5.4 Scaling results for a direct solver with `ne = 256`, `pT = pp = 1`, `beta = 0.2` averaged over `number = 10` calculations using a local [conda](../01_introduction/1.1_overview.ipynb) installation of the software on a dedicated machine.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cb9694",
   "metadata": {},
   "source": [
    "#### Case 2a - Direct\n",
    "\n",
    "Time constraints mean we do not run case 2a (temperature-dependent rheology with Ra $=10^4$) but do present some previously run results below and compare direct and iterative solver strategies.  Uncommenting the cells below will allow them to be tested interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955c5302-7f4c-4c6a-a572-80c2e0d3657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxtimes_2a = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8178f3-c851-4fa4-a224-981a02ed8a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # case 2a\n",
    "# Ra = 1.e4\n",
    "# b=np.log(1.e3) # temperature dependent viscosity\n",
    "\n",
    "# maxtimes_2a['Direct Stokes'] = utils.ipp.profile_parallel(nprocs_scale, steps, path, 'background.blankenbach', 'solve_blankenbach', \n",
    "#                                                         Ra, ne, pp=pp, pT=pT, b=b, beta=beta, number=number,\n",
    "#                                                         output_filename=output_folder / 'blankenbach_scaling_direct_2a.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b25c6-d53d-4da8-aeeb-341ba46e868c",
   "metadata": {},
   "source": [
    "As before, if run interactively, the behavior of the scaling test will strongly depend on the computational resources available on the machine where this notebook is run.\n",
    "\n",
    "For comparison we provide the output of this notebook using `ne = 256`, `pT = pp = 1`, `beta = 0.2` and `number = 10` in Figure 2.5.6 generated on a dedicated machine using a local [conda](../01_introduction/1.1_overview.ipynb) installation of the software.\n",
    "\n",
    "![Direct Scaling](images/blankenbach_scaling_direct_2a.png)\n",
    "\n",
    "*Figure 2.5.6 Scaling results for a direct solver with `ne = 256`, `pT = pp = 1`, `beta = 0.2` averaged over `number = 10` calculations using a local [conda](../01_introduction/1.1_overview.ipynb) installation of the software on a dedicated machine.*\n",
    "\n",
    "We can see in Figure 2.5.6 that assembly scales well.  The improved scaling behavior of the solves seen in case 1a is seen again and may even be marginally improved.  This is likely because case 2a takes more iterations, further re-distributing the cost of the analysis step taken on the first iteration.\n",
    "\n",
    "We also need to test that we are still converging to the benchmark solutions in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e299df1b-357e-4947-b8fe-87232e540d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases = ['2a']\n",
    "# errors_all = utils.ipp.run_parallel(nprocs_conv, path, 'background.blankenbach', 'convergence_errors', pTs, nelements, cases, beta=beta)\n",
    "\n",
    "# for errors in errors_all:\n",
    "#     fits = plot_convergence(pTs, nelements, errors)\n",
    "#     assert(all(fit > 1.0 for fits_p in fits.values() for fits_l in fits_p for fit in fits_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680ecea-1a14-4e72-af2a-a26efaf77e01",
   "metadata": {},
   "source": [
    "#### Case 2a - Iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074b2da5-8f0e-4339-a405-de1d95729c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Case 2a\n",
    "# Ra = 1.e4\n",
    "# b=np.log(1.e3)\n",
    "# petsc_options_s = {'ksp_type':'minres', \n",
    "#                    'ksp_rtol': 5.e-9,\n",
    "#                    'pc_type':'fieldsplit', \n",
    "#                    'pc_fieldsplit_type': 'additive',\n",
    "#                    'fieldsplit_v_ksp_type':'preonly',\n",
    "#                    'fieldsplit_v_pc_type':'gamg',\n",
    "#                    'fieldsplit_p_ksp_type':'preonly',\n",
    "#                    'fieldsplit_p_pc_type':'jacobi'}\n",
    "\n",
    "# maxtimes_2a['Iterative Stokes'] = utils.ipp.profile_parallel(nprocs_scale, steps, path, 'background.blankenbach', 'solve_blankenbach', \n",
    "#                                                         Ra, ne, pp=pp, pT=pT, b=b, beta=beta, \n",
    "#                                                         petsc_options_s=petsc_options_s,\n",
    "#                                                         attach_nullspace=True, \n",
    "#                                                         number=number,\n",
    "#                                                         output_filename=output_folder / 'blankenbach_scaling_iterative_2a.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a2f13-8899-40c4-9ad3-5d354cfb892c",
   "metadata": {},
   "source": [
    "If sufficient computational resources are available when running this cell interactively this should show that the iterative method scales better than the direct method but has a much higher absolute cost (wall time).  \n",
    "\n",
    "For reference we provide the output of this notebook using `ne = 256`, `pT = pp = 1`, `beta = 0.2` and `number = 10` in Figure 2.5.7 generated on a dedicated machine using a local [conda](../01_introduction/1.1_overview.ipynb) installation of the software.\n",
    "\n",
    "![Iterative Scaling](images/blankenbach_scaling_iterative_2a.png)\n",
    "\n",
    "*Figure 2.5.7 Scaling results for a direct solver with `ne = 256`, `pT = pp = 1`, `beta = 0.2` averaged over `number = 10` calculations using a local [conda](../01_introduction/1.1_overview.ipynb) installation of the software on a dedicated machine.*\n",
    "\n",
    "Here we can see the improved scaling (for the Stokes solve, the temperature is still using a direct method) but hugely increased cost.  This increase is even more significant here as the higher degree of non-linearity in case 2a compared to 1a has increased the number of nonlinear iterations taken.\n",
    "\n",
    "We also test if the iterative method is converging to the benchmark solution below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b1449-1188-4989-9ef6-df9a5daa7b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases = ['2a']\n",
    "# errors_all = utils.ipp.run_parallel(nprocs_conv, path, \n",
    "#                                     'background.blankenbach', 'convergence_errors', pTs, nelements, cases, beta=beta,\n",
    "#                                     petsc_options_s=petsc_options_s, \n",
    "#                                     attach_nullspace=True)\n",
    "\n",
    "# for errors in errors_all:\n",
    "#     fits = plot_convergence(pTs, nelements, errors)\n",
    "#     assert(all(fit > 1.0 for fits_p in fits.values() for fits_l in fits_p for fit in fits_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ee3ea6",
   "metadata": {},
   "source": [
    "#### Case 2a - Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75098b3a-b4ec-4ce8-bf96-c40da48ec46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # choose which steps to compare\n",
    "# compare_steps = ['Assemble Stokes', 'Solve Stokes']\n",
    "\n",
    "# # set up a figure for plotting\n",
    "# fig, axs = pl.subplots(nrows=len(compare_steps), figsize=[6.4,4.8*len(compare_steps)], sharex=True)\n",
    "# if len(compare_steps) == 1: axs = [axs]\n",
    "# for i, step in enumerate(compare_steps):\n",
    "#     s = steps.index(step)\n",
    "#     for name, lmaxtimes in maxtimes_2a.items():\n",
    "#         axs[i].plot(nprocs_scale, [t[s] for t in lmaxtimes], 'o-', label=name)\n",
    "#     axs[i].set_title(step)\n",
    "#     axs[i].legend()\n",
    "#     axs[i].set_ylabel('wall time (s)')\n",
    "#     axs[i].grid()\n",
    "# axs[-1].set_xlabel('number processors')\n",
    "# # save the figure\n",
    "# fig.savefig(output_folder / 'blankenbach_scaling_comparison_2a.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e6ad62-2df4-404f-af19-1281a657c3b1",
   "metadata": {},
   "source": [
    "If running interactively with sufficient computational resources we will see that both methods have approximately the same assembly costs but the iterative methods wall time costs are substantially higher and never become competitive despite scaling better at higher number of processors due to the improved scaling of reapplying the direct method.\n",
    "\n",
    "For reference we provide the output of this notebook using `ne = 256`, `pT = pp = 1`, `beta = 0.2` and `number = 10` in Figure 2.5.8 generated on a dedicated machine using a local [conda](../01_introduction/1.1_overview.ipynb) installation of the software.\n",
    "\n",
    "![Scaling Comparison](images/blankenbach_scaling_comparison_2a.png)\n",
    "\n",
    "*Figure 2.5.8 Scaling results for a direct solver with `ne = 256`, `pT = pp = 1`, `beta = 0.2` averaged over `number = 10` calculations using a local [conda](../01_introduction/1.1_overview.ipynb) installation of the software on a dedicated machine.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc849b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
